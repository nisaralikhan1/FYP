{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers tensorflow streamlit pyngrok numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2GgHrUiU5X3",
        "outputId": "f9f9448e-b4c0-4b08-8ce4-a237d5f9d110"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.51.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.4.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.11.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.28.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading streamlit-1.51.0-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.4.1-py3-none-any.whl (25 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.4.1 streamlit-1.51.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from transformers import TFRobertaForSequenceClassification, RobertaTokenizerFast\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load model & tokenizer\n",
        "model = TFRobertaForSequenceClassification.from_pretrained(\"./saved_emotion_model\")\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"./saved_emotion_tokenizer\")\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.classes_ = [\n",
        "    \"sadness\",\n",
        "    \"joy\",\n",
        "    \"love\",\n",
        "    \"anger\",\n",
        "    \"fear\",\n",
        "    \"surprise\"\n",
        "]\n",
        "\n",
        "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "\n",
        "print(\"Model, tokenizer, and label encoder saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US7yE6RS1tgr",
        "outputId": "9d3bd05d-253e-413f-c2d2-3e539e3e7c1e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model, tokenizer, and label encoder saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkWt2HUNUE3m",
        "outputId": "b2435951-22d0-4ef3-e488-a7e9cc607b03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing streamlit_app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "from transformers import TFRobertaForSequenceClassification, RobertaTokenizerFast\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# Load model & tokenizer\n",
        "model = TFRobertaForSequenceClassification.from_pretrained(\"./saved_emotion_model\")\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"./saved_emotion_tokenizer\")\n",
        "\n",
        "# Load label encoder\n",
        "with open(\"label_encoder.pkl\", \"rb\") as f:\n",
        "    label_encoder = pickle.load(f)\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"Emotion Detection App\")\n",
        "st.write(\"Enter a sentence and get the predicted emotion.\")\n",
        "\n",
        "user_input = st.text_input(\"Type your sentence here:\")\n",
        "\n",
        "if st.button(\"Predict\"):\n",
        "    if user_input.strip() != \"\":\n",
        "        # Tokenize input\n",
        "        inputs = tokenizer(user_input, return_tensors=\"tf\", truncation=True, padding=True, max_length=128)\n",
        "        outputs = model(inputs)\n",
        "        # Get prediction probabilities\n",
        "        prediction = tf.nn.softmax(outputs.logits, axis=-1).numpy()[0]\n",
        "\n",
        "        # Identify the top predicted class\n",
        "        predicted_class = np.argmax(prediction)\n",
        "        predicted_label = label_encoder.classes_[predicted_class]\n",
        "\n",
        "        # Get confidence percentage\n",
        "        confidence = prediction[predicted_class] * 100\n",
        "\n",
        "        # Display result\n",
        "        st.success(f\"Predicted Emotion: {predicted_label} ({confidence:.2f}% confidence)\")\n",
        "\n",
        "    else:\n",
        "        st.warning(\"Please enter a sentence.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 318dey8I8ExqyGMTqpm5zcG7NDi_88uEhCXojb1snZAKF6xCs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPn-YiHCyApK",
        "outputId": "7de45226-8117-4a5b-dcfc-4a81dbe584b8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "!killall ngrok\n",
        "# Run streamlit on port 8501\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "print(f\"Streamlit app available at: {public_url}\")\n",
        "\n",
        "!streamlit run streamlit_app.py --server.port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rfafQt_Yq5s",
        "outputId": "3fcae05d-5b9e-4d9b-9350-7f18b1653fb6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok: no process found\n",
            "Streamlit app available at: NgrokTunnel: \"https://35bfc4a4df26.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.236.134.193:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2025-11-12 17:54:29.432660: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762970069.459183    4797 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762970069.466902    4797 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762970069.487960    4797 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762970069.488005    4797 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762970069.488011    4797 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762970069.488015    4797 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-12 17:54:38.281526: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./saved_emotion_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-11-12T18:05:17+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-60ff96b0-9f0f-4973-8e5d-9c1a90db9315 acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}
